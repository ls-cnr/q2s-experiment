#!/usr/bin/env python3
"""
Pipeline Step 2.1: Data Analysis Pre-Processing
This script processes the scenarios.csv file generated by pipeline1_scenario_generator.py
and creates a pre-processed version where rows differing only by alpha are grouped together.

The transformation groups rows that are identical except for the alpha value and creates
separate columns for ScorePlan results for each alpha value (0.3, 0.5, 0.7).

Example transformation:
Input rows with alpha=0.3, 0.5, 0.7 but identical other values become:
- Score0_3Plan_ID, Score0_3Plan_success, Score0_3Plan_margins (from alpha=0.3 row)
- Score0_5Plan_ID, Score0_5Plan_success, Score0_5Plan_margins (from alpha=0.5 row)
- Score0_7Plan_ID, Score0_7Plan_success, Score0_7Plan_margins (from alpha=0.7 row)
- AvgPlan, MinPlan, RndPlan columns (taken from any row in the group)
"""

import argparse
import json
import pandas as pd
import os
from pathlib import Path


def load_config(config_file):
    """Load configuration from JSON file."""
    with open(config_file, 'r') as f:
        return json.load(f)


def preprocess_scenarios(scenarios_df, config):
    """Transform the scenarios dataframe by grouping alpha values."""

    # Group by scenario characteristics (excluding ID and alpha)
    grouping_cols = [
        'cost_constraint',
        'effort_constraint',
        'time_constraint',
        'cost_constraint_perturbation',
        'effort_constraint_perturbation',
        'time_constraint_perturbation',
        'num_valid_plans'
    ]

    # Initialize result dataframe
    result_rows = []

    # Group by scenario characteristics
    grouped = scenarios_df.groupby(grouping_cols)

    for group_key, group_df in grouped:
        # Create new row for this group
        new_row = {}

        # Add the grouping columns
        for i, col in enumerate(grouping_cols):
            new_row[col] = group_key[i]

        # Process ScorePlan columns for each alpha
        alpha_values = sorted(group_df['alpha'].unique())
        for alpha in alpha_values:
            alpha_str = str(alpha).replace('.', '_')
            alpha_row = group_df[group_df['alpha'] == alpha]

            if not alpha_row.empty:
                row = alpha_row.iloc[0]
                new_row[f'Score{alpha_str}Plan_ID'] = row['ScorePlan_ID']
                new_row[f'Score{alpha_str}Plan_success'] = row['ScorePlan_success']
                new_row[f'Score{alpha_str}Plan_margins'] = row['ScorePlan_margins']
            else:
                # Handle missing alpha values
                new_row[f'Score{alpha_str}Plan_ID'] = None
                new_row[f'Score{alpha_str}Plan_success'] = None
                new_row[f'Score{alpha_str}Plan_margins'] = None

        # Add other plan columns (assuming they're the same for all alphas)
        first_row = group_df.iloc[0]
        for prefix in ['AvgPlan', 'MinPlan', 'RndPlan']:
            new_row[f'{prefix}_ID'] = first_row[f'{prefix}_ID']
            new_row[f'{prefix}_success'] = first_row[f'{prefix}_success']
            new_row[f'{prefix}_margins'] = first_row[f'{prefix}_margins']

        result_rows.append(new_row)

    # Create result dataframe
    result_df = pd.DataFrame(result_rows)

    # Add ID column
    result_df.reset_index(drop=True, inplace=True)
    result_df.insert(0, 'ID', range(1, len(result_df) + 1))

    return result_df


def main():
    parser = argparse.ArgumentParser(
        description="Pre-process scenarios data by grouping alpha values"
    )
    parser.add_argument(
        'config_file',
        help='Path to the configuration JSON file'
    )

    args = parser.parse_args()

    # Load configuration
    config = load_config(args.config_file)

    # Get file paths
    output_dir = config['simulation_settings']['output_directory']
    scenarios_file = config['simulation_settings']['scenarios_filename']
    scenarios_path = os.path.join(output_dir, scenarios_file)

    # Check if scenarios file exists
    if not os.path.exists(scenarios_path):
        raise FileNotFoundError(f"Scenarios file not found: {scenarios_path}")

    # Load scenarios data
    print(f"Loading scenarios from: {scenarios_path}")
    scenarios_df = pd.read_csv(scenarios_path)

    print(f"Loaded {len(scenarios_df)} scenarios with columns: {list(scenarios_df.columns)}")

    # Preprocess the data
    print("Pre-processing scenarios...")
    preprocessed_df = preprocess_scenarios(scenarios_df, config)

    # Save preprocessed data
    output_file = os.path.join(output_dir, 'pre_processed_scenarios.csv')
    preprocessed_df.to_csv(output_file, index=False)

    print(f"Pre-processed data saved to: {output_file}")
    print(f"Generated {len(preprocessed_df)} grouped scenarios")
    print(f"Columns in output: {list(preprocessed_df.columns)}")


if __name__ == "__main__":
    main()
