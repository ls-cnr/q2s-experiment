#!/usr/bin/env python3
"""
Pipeline Step 2.1: Data Analysis Pre-Processing
This script processes the scenarios.csv file generated by pipeline1_scenario_generator.py
and creates a pre-processed version where rows differing only by alpha are grouped together.

The transformation groups rows that are identical except for the alpha value and creates
separate columns for ScorePlan results for each alpha value (0.3, 0.5, 0.7).

Additionally, it generates a scenarios_summary.csv file that compares all strategies
including Min (alpha=0), alpha values (0.3, 0.5, 0.7), Avg (alpha=1), and Random.

Example transformation:
Input rows with alpha=0.3, 0.5, 0.7 but identical other values become:
- Score0_3Plan_ID, Score0_3Plan_success, Score0_3Plan_margins (from alpha=0.3 row)
- Score0_5Plan_ID, Score0_5Plan_success, Score0_5Plan_margins (from alpha=0.5 row)
- Score0_7Plan_ID, Score0_7Plan_success, Score0_7Plan_margins (from alpha=0.7 row)
- AvgPlan, MinPlan, RndPlan columns (taken from any row in the group)
"""

import argparse
import json
import pandas as pd
import numpy as np
import os
from pathlib import Path


def load_config(config_file):
    """Load configuration from JSON file."""
    with open(config_file, 'r') as f:
        return json.load(f)


def get_domain_variables(config):
    """Extract domain variable names from quality goals."""
    quality_goals = config.get('quality_goals', [])
    domain_variables = []

    for qg in quality_goals:
        domain_variable = qg.get('column_name', qg.get('domain_variable'))
        if domain_variable:
            domain_variables.append(domain_variable)

    return domain_variables


def calculate_strategy_metrics(df, strategy_prefix):
    """Calculate metrics for a given strategy."""
    success_col = f"{strategy_prefix}_success"
    margins_col = f"{strategy_prefix}_margins"

    if success_col not in df.columns or margins_col not in df.columns:
        return {
            'success_rate': 0.0,
            'avg_margin': 0.0,
            'avg_margin_when_success': 0.0
        }

    # Calculate success rate
    success_rate = df[success_col].mean()

    # Get all margins (as single numeric values, not lists)
    all_margins = df[margins_col].dropna().tolist()

    # Get margins only for successful cases
    success_margins = df[df[success_col] == 1][margins_col].dropna().tolist()

    # Calculate average margins
    avg_margin = np.mean(all_margins) if all_margins else 0.0
    avg_margin_when_success = np.mean(success_margins) if success_margins else 0.0

    return {
        'success_rate': success_rate,
        'avg_margin': avg_margin,
        'avg_margin_when_success': avg_margin_when_success
    }


def generate_scenarios_summary(preprocessed_df, output_dir):
    """Generate scenarios summary comparing all strategies."""

    # Ensure tables directory exists
    tables_dir = os.path.join(output_dir, 'tables')
    os.makedirs(tables_dir, exist_ok=True)

    # Define strategies to analyze
    strategies = {
        'Min (alfa 0)': 'MinPlan',
        'alfa 0.3': 'Score0_3Plan',
        'alfa 0.5': 'Score0_5Plan',
        'alfa 0.7': 'Score0_7Plan',
        'Avg (alfa 1)': 'AvgPlan',
        'Rnd': 'RndPlan'
    }

    # Calculate metrics for each strategy
    summary_data = {
        'Strategy': ['Success Rate', 'Avg Margin', 'Avg Margin (when success)']
    }

    for strategy_name, strategy_prefix in strategies.items():
        metrics = calculate_strategy_metrics(preprocessed_df, strategy_prefix)

        summary_data[strategy_name] = [
            metrics['success_rate'],
            metrics['avg_margin'],
            metrics['avg_margin_when_success']
        ]

    # Create summary dataframe
    summary_df = pd.DataFrame(summary_data)

    # Save summary file
    summary_file = os.path.join(tables_dir, 'scenarios_summary.csv')
    summary_df.to_csv(summary_file, index=False, sep=';', float_format='%.9f')

    print(f"Summary file saved to: {summary_file}")

    # Print summary to console
    print("\nScenarios Summary:")
    print(summary_df.to_string(index=False, float_format='%.9f'))

    return summary_df


def preprocess_scenarios(scenarios_df, config):
    """Transform the scenarios dataframe by grouping alpha values."""

    # Get domain variables dynamically from config
    domain_variables = get_domain_variables(config)

    print(f"Domain variables from config: {domain_variables}")

    # Group by scenario characteristics (excluding ID and alpha)
    grouping_cols = []

    # Add constraint columns
    grouping_cols.extend(domain_variables)

    # Add perturbation columns
    grouping_cols.extend([f"{var}_perturbation" for var in domain_variables])

    # Add num_valid_plans
    grouping_cols.append('num_valid_plans')

    print(f"Grouping by columns: {grouping_cols}")

    # Verify all columns exist in the dataframe
    missing_cols = [col for col in grouping_cols if col not in scenarios_df.columns]
    if missing_cols:
        raise ValueError(f"Missing columns in scenarios data: {missing_cols}")

    # Initialize result dataframe
    result_rows = []

    # Group by scenario characteristics
    grouped = scenarios_df.groupby(grouping_cols)

    for group_key, group_df in grouped:
        # Create new row for this group
        new_row = {}

        # Add the grouping columns
        for i, col in enumerate(grouping_cols):
            new_row[col] = group_key[i]

        # Process ScorePlan columns for each alpha
        alpha_values = sorted(group_df['alpha'].unique())
        for alpha in alpha_values:
            alpha_str = str(alpha).replace('.', '_')
            alpha_row = group_df[group_df['alpha'] == alpha]

            if not alpha_row.empty:
                row = alpha_row.iloc[0]
                new_row[f'Score{alpha_str}Plan_ID'] = row['ScorePlan_ID']
                new_row[f'Score{alpha_str}Plan_success'] = row['ScorePlan_success']
                new_row[f'Score{alpha_str}Plan_margins'] = row['ScorePlan_margins']
            else:
                # Handle missing alpha values
                new_row[f'Score{alpha_str}Plan_ID'] = None
                new_row[f'Score{alpha_str}Plan_success'] = None
                new_row[f'Score{alpha_str}Plan_margins'] = None

        # Add other plan columns (assuming they're the same for all alphas)
        first_row = group_df.iloc[0]
        for prefix in ['AvgPlan', 'MinPlan', 'RndPlan']:
            new_row[f'{prefix}_ID'] = first_row[f'{prefix}_ID']
            new_row[f'{prefix}_success'] = first_row[f'{prefix}_success']
            new_row[f'{prefix}_margins'] = first_row[f'{prefix}_margins']

        result_rows.append(new_row)

    # Create result dataframe
    result_df = pd.DataFrame(result_rows)

    # Add ID column
    result_df.reset_index(drop=True, inplace=True)
    result_df.insert(0, 'ID', range(1, len(result_df) + 1))

    return result_df


def main():
    parser = argparse.ArgumentParser(
        description="Pre-process scenarios data by grouping alpha values and generate summary"
    )
    parser.add_argument(
        'config_file',
        help='Path to the configuration JSON file'
    )

    args = parser.parse_args()

    # Load configuration
    config = load_config(args.config_file)

    # Get file paths
    output_dir = config['simulation_settings']['output_directory']
    scenarios_file = config['simulation_settings']['scenarios_filename']
    scenarios_path = os.path.join(output_dir, scenarios_file)

    # Check if scenarios file exists
    if not os.path.exists(scenarios_path):
        raise FileNotFoundError(f"Scenarios file not found: {scenarios_path}")

    # Load scenarios data
    print(f"Loading scenarios from: {scenarios_path}")
    scenarios_df = pd.read_csv(scenarios_path)

    print(f"Loaded {len(scenarios_df)} scenarios with columns: {list(scenarios_df.columns)}")

    # Preprocess the data
    print("Pre-processing scenarios...")
    preprocessed_df = preprocess_scenarios(scenarios_df, config)

    # Save preprocessed data
    output_file = os.path.join(output_dir, 'pre_processed_scenarios.csv')
    preprocessed_df.to_csv(output_file, index=False)

    print(f"Pre-processed data saved to: {output_file}")
    print(f"Generated {len(preprocessed_df)} grouped scenarios")
    print(f"Columns in output: {list(preprocessed_df.columns)}")

    # Generate scenarios summary
    print("\nGenerating scenarios summary...")
    summary_df = generate_scenarios_summary(preprocessed_df, output_dir)


if __name__ == "__main__":
    main()
